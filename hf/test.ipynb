{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from langchain.llms import VertexAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Given this text, decide what is the issue the customer is concerned about. Valid categories are these:\n",
    "* product issues\n",
    "* delivery problems\n",
    "* missing or late orders\n",
    "* wrong product\n",
    "* cancellation request\n",
    "* refund or exchange\n",
    "* bad support experience\n",
    "* no clear reason to be upset\n",
    "\n",
    "Text: {email}\n",
    "Category:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"email\"])\n",
    "llm = VertexAI()\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "print(llm_chain.run(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/wn/qnn9lpvn7ds_v_jkgk6qs1400000gn/T/ipykernel_76201/3995972475.py\", line 20, in <module>\n",
      "    emotions = load_dataset('SetFit/emotion')\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/datasets/load.py\", line 2523, in load_dataset\n",
      "    builder_instance = load_dataset_builder(\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/datasets/load.py\", line 2195, in load_dataset_builder\n",
      "    dataset_module = dataset_module_factory(\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/datasets/load.py\", line 1846, in dataset_module_factory\n",
      "    raise e1 from None\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/datasets/load.py\", line 1828, in dataset_module_factory\n",
      "    ).get_module()\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/datasets/load.py\", line 1208, in get_module\n",
      "    patterns = get_data_patterns(base_path, download_config=self.download_config)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/datasets/data_files.py\", line 473, in get_data_patterns\n",
      "    return _get_data_files_patterns(resolver)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/datasets/data_files.py\", line 260, in _get_data_files_patterns\n",
      "    data_files = pattern_resolver(pattern)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/datasets/data_files.py\", line 344, in resolve_pattern\n",
      "    fs, _, _ = get_fs_token_paths(pattern, storage_options=storage_options)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/fsspec/core.py\", line 653, in get_fs_token_paths\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py\", line 393, in glob\n",
      "    return super().glob(path, **kwargs)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/fsspec/spec.py\", line 606, in glob\n",
      "    # for shell globbing details.\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/fsspec/utils.py\", line 734, in glob_translate\n",
      "ValueError: Invalid pattern: '**' can only be an entire path component\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/aayushsonkar/Desktop/Grind/2023-2024/Me/Syncwise/ML/main/syncwise/venv/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Example tokenization\n",
    "inputs = tokenizer(['Hello world', 'Hi how are you'], padding=True, truncation=True, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Load emotions dataset\n",
    "emotions = load_dataset('SetFit/emotion')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "# Tokenize and encode emotions dataset\n",
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n",
    "emotions_encoded.set_format('pt', columns=['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# PyTorch DataLoader for train set\n",
    "train_dataset = TensorDataset(\n",
    "    emotions_encoded['train']['input_ids'],\n",
    "    emotions_encoded['train']['attention_mask'],\n",
    "    emotions_encoded['train']['token_type_ids'],\n",
    "    emotions_encoded['train']['label']\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# PyTorch DataLoader for test set\n",
    "test_dataset = TensorDataset(\n",
    "    emotions_encoded['test']['input_ids'],\n",
    "    emotions_encoded['test']['attention_mask'],\n",
    "    emotions_encoded['test']['token_type_ids'],\n",
    "    emotions_encoded['test']['label']\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Example batch from train_dataloader\n",
    "batch = next(iter(train_dataloader))\n",
    "input_ids, attention_mask, token_type_ids, labels = batch\n",
    "print(input_ids, '\\n\\n', labels)\n",
    "\n",
    "# BERT for classification model in PyTorch\n",
    "class BERTForClassification(torch.nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(BERTForClassification, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = torch.nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Instantiate the model\n",
    "num_classes = 6\n",
    "classifier = BERTForClassification(model, num_classes)\n",
    "\n",
    "# Set optimizer and loss function\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    classifier.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = classifier(input_ids, attention_mask, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate on the test set\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        logits = classifier(input_ids, attention_mask, token_type_ids)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        accuracy = torch.sum(predictions == labels).item() / len(labels)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
